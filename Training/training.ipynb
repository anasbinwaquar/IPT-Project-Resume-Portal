{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd075a7ac96e870769fac4c5bf6991215d851f962e5b4301c46660a6dee9e2a8ccd",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "75a7ac96e870769fac4c5bf6991215d851f962e5b4301c46660a6dee9e2a8ccd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Resume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Data Science</td>\n      <td>Skills * Programming Languages: Python (pandas...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Science</td>\n      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Science</td>\n      <td>Areas of Interest Deep Learning, Control Syste...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Science</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data Science</td>\n      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#loading the dataset and analysis the field of the dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "resumeDataSet = pd.read_csv('UpdatedResumeDataSet.csv', encoding = 'utf-8')\n",
    "resumeDataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Displaying the distinct categories of resume -\n['Data Science' 'HR' 'Advocate' 'Arts' 'Web Designing'\n 'Mechanical Engineer' 'Sales' 'Health and fitness' 'Civil Engineer'\n 'Java Developer' 'Business Analyst' 'SAP Developer' 'Automation Testing'\n 'Electrical Engineering' 'Operations Manager' 'Python Developer'\n 'DevOps Engineer' 'Network Security Engineer' 'PMO' 'Database' 'Hadoop'\n 'ETL Developer' 'DotNet Developer' 'Blockchain' 'Testing']\n"
     ]
    }
   ],
   "source": [
    "#Idendtifying all the resume categories in the dataset\n",
    "\n",
    "print (\"Displaying the distinct categories of resume -\")\n",
    "print (resumeDataSet['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Displaying the distinct categories of resume and the number of records belonging to each category -\nJava Developer               84\nTesting                      70\nDevOps Engineer              55\nPython Developer             48\nWeb Designing                45\nHR                           44\nHadoop                       42\nMechanical Engineer          40\nETL Developer                40\nBlockchain                   40\nData Science                 40\nOperations Manager           40\nSales                        40\nArts                         36\nDatabase                     33\nHealth and fitness           30\nElectrical Engineering       30\nPMO                          30\nBusiness Analyst             28\nDotNet Developer             28\nAutomation Testing           26\nNetwork Security Engineer    25\nSAP Developer                24\nCivil Engineer               24\nAdvocate                     20\nName: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Displaying the distinct categories of resume and the number of records belonging to each category -\n",
    "\n",
    "print (\"Displaying the distinct categories of resume and the number of records belonging to each category -\")\n",
    "print (resumeDataSet['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing function to clean reusme removing URL,HASH TAGS, PUNCTUATIONS,etc\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def cleanResume(resumeText):\n",
    "      \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemming = PorterStemmer()\n",
    "    resumeText = resumeText.lower()\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText)\n",
    "    resumeText = re.sub(r'[0-9]',' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    word_tokens = word_tokenize(resumeText) \n",
    "    resumeText = [w for w in word_tokens if not w in stopwords.words(\"english\")]\n",
    "    resumeText = ' '.join(map(str, resumeText))\n",
    "    resumeText = stemming.stem(resumeText)\n",
    "    resumeText = lemmatizer.lemmatize(resumeText)\n",
    "    return resumeText\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pre processing of resume in progress.......\n",
      "Pre-processing DONE !!!!\n"
     ]
    }
   ],
   "source": [
    "#Pre Processing the resumes\n",
    "print(\"Pre processing of resume in progress.......\")\n",
    "resumeDataSet['cleaned_resume'] = resumeDataSet.Resume.apply(lambda x: cleanResume(x))\n",
    "print(\"Pre-processing DONE !!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature completed .....\n(769, 1500)\n(193, 1500)\n"
     ]
    }
   ],
   "source": [
    "#Making tf idf vectors and also splitting the data to train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "\n",
    "requiredText = resumeDataSet['cleaned_resume'].values\n",
    "requiredTarget = resumeDataSet['Category'].values\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    stop_words='english',\n",
    "    max_features=1500)\n",
    "word_vectorizer.fit(requiredText)\n",
    "WordFeatures = word_vectorizer.transform(requiredText)\n",
    "with open('tf_idf', 'wb') as tfidf:\n",
    "  pickle.dump(word_vectorizer, tfidf)\n",
    "\n",
    "\n",
    "print (\"Feature completed .....\")\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=0, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                           precision    recall  f1-score   support\n\n                 Advocate       1.00      1.00      1.00         3\n                     Arts       1.00      1.00      1.00         3\n       Automation Testing       1.00      1.00      1.00         5\n               Blockchain       1.00      1.00      1.00         9\n         Business Analyst       1.00      1.00      1.00         6\n           Civil Engineer       1.00      1.00      1.00         5\n             Data Science       1.00      1.00      1.00         9\n                 Database       1.00      1.00      1.00         7\n          DevOps Engineer       1.00      1.00      1.00        11\n         DotNet Developer       1.00      1.00      1.00         9\n            ETL Developer       1.00      1.00      1.00         8\n   Electrical Engineering       1.00      1.00      1.00         9\n                       HR       1.00      1.00      1.00         5\n                   Hadoop       1.00      1.00      1.00         9\n       Health and fitness       1.00      1.00      1.00         7\n           Java Developer       1.00      1.00      1.00        19\n      Mechanical Engineer       1.00      1.00      1.00         3\nNetwork Security Engineer       1.00      1.00      1.00         4\n       Operations Manager       1.00      1.00      1.00         5\n                      PMO       1.00      1.00      1.00         6\n         Python Developer       1.00      1.00      1.00        11\n            SAP Developer       1.00      1.00      1.00         4\n                    Sales       1.00      1.00      1.00        13\n                  Testing       1.00      1.00      1.00        15\n            Web Designing       1.00      1.00      1.00         8\n\n                 accuracy                           1.00       193\n                macro avg       1.00      1.00      1.00       193\n             weighted avg       1.00      1.00      1.00       193\n\nAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM classifier model\n",
    "# Printing the classification report and accuracy\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",svclassifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['svm_trained_model']"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#Saving the trained model in the file so can be used in the other program to cateogrise the cv in computer and finding relevant cv basis of job description\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(svclassifier,'svm_trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                           precision    recall  f1-score   support\n\n                 Advocate       1.00      1.00      1.00         3\n                     Arts       1.00      1.00      1.00         3\n       Automation Testing       1.00      1.00      1.00         5\n               Blockchain       1.00      1.00      1.00         9\n         Business Analyst       1.00      1.00      1.00         6\n           Civil Engineer       1.00      1.00      1.00         5\n             Data Science       1.00      1.00      1.00         9\n                 Database       1.00      1.00      1.00         7\n          DevOps Engineer       1.00      1.00      1.00        11\n         DotNet Developer       1.00      1.00      1.00         9\n            ETL Developer       1.00      1.00      1.00         8\n   Electrical Engineering       1.00      1.00      1.00         9\n                       HR       1.00      1.00      1.00         5\n                   Hadoop       1.00      1.00      1.00         9\n       Health and fitness       1.00      1.00      1.00         7\n           Java Developer       1.00      1.00      1.00        19\n      Mechanical Engineer       1.00      1.00      1.00         3\nNetwork Security Engineer       1.00      1.00      1.00         4\n       Operations Manager       1.00      1.00      1.00         5\n                      PMO       1.00      1.00      1.00         6\n         Python Developer       1.00      1.00      1.00        11\n            SAP Developer       1.00      1.00      1.00         4\n                    Sales       1.00      1.00      1.00        13\n                  Testing       1.00      1.00      1.00        15\n            Web Designing       1.00      1.00      1.00         8\n\n                 accuracy                           1.00       193\n                macro avg       1.00      1.00      1.00       193\n             weighted avg       1.00      1.00      1.00       193\n\nAccuracy: 0.9896373056994818\n"
     ]
    }
   ],
   "source": [
    "# Training the Logistic Regression model\n",
    "# Printing the classification report and accuracy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Logistic_model = LogisticRegression()\n",
    "Logistic_model = Logistic_model.fit(X_train,y_train)\n",
    "y_preds = Logistic_model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",Logistic_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Logistic_trained_model']"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "#Saving the trained model in the file so can be used in the other program to cateogrise the cv in computer and finding relevant cv basis of job description\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(Logistic_model,'Logistic_trained_model')\n"
   ]
  }
 ]
}